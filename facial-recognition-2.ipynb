{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load your dataset\n#rescale=1./255\ntrain_datagen = ImageDataGenerator(\n    #rescale=1./255,            # Normalizing pixel values\n  #  rotation_range=40,         # Randomly rotating images in the range (degrees, 0 to 180)         # Applying shear transformations\n   # zoom_range=0.2,            # Randomly zooming inside pictures\n    #horizontal_flip=True,      # Randomly flipping half of the images horizontally\n    validation_split=0.2\n)\ntrain_generator = train_datagen.flow_from_directory(\n        '/kaggle/input/face-classification-deep-learning/dataset/train',\n        target_size=(224, 224),\n        batch_size=64,\n        class_mode='categorical',\n        subset='training')\nvalidation_generator = train_datagen.flow_from_directory(\n        '/kaggle/input/face-classification-deep-learning/dataset/train',\n        target_size=(224, 224),\n        batch_size=64,\n        class_mode='categorical',\n        subset='validation')\n\n# Define the model\n#base_model = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n#base_model.trainable = False  # Freeze the convolutional base\n\n#model = models.Sequential([\n   # base_model,\n  #  layers.GlobalAveragePooling2D(),\n #   layers.Dense(7000, activation='softmax')\n\n    #]#)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-08T19:01:52.306232Z","iopub.execute_input":"2023-11-08T19:01:52.306855Z","iopub.status.idle":"2023-11-08T19:02:32.497961Z","shell.execute_reply.started":"2023-11-08T19:01:52.306826Z","shell.execute_reply":"2023-11-08T19:02:32.497115Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Found 112000 images belonging to 7000 classes.\nFound 28000 images belonging to 7000 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D,Dropout,Flatten,Activation\ndef vgg_face():\t\n    model = Sequential()\n    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n    model.add(Convolution2D(64, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(128, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(Convolution2D(512, (7, 7), activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Convolution2D(7000, (1, 1)))\n    model.add(Flatten())\n    model.add(Activation('softmax'))\n    \n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-08T19:18:27.267565Z","iopub.execute_input":"2023-11-08T19:18:27.268400Z","iopub.status.idle":"2023-11-08T19:18:27.287705Z","shell.execute_reply.started":"2023-11-08T19:18:27.268364Z","shell.execute_reply":"2023-11-08T19:18:27.286914Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model = vgg_face()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T19:18:27.517234Z","iopub.execute_input":"2023-11-08T19:18:27.517554Z","iopub.status.idle":"2023-11-08T19:18:27.874446Z","shell.execute_reply.started":"2023-11-08T19:18:27.517526Z","shell.execute_reply":"2023-11-08T19:18:27.873524Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"sequential_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n zero_padding2d_143 (ZeroPad  (None, 226, 226, 3)      0         \n ding2D)                                                         \n                                                                 \n conv2d_166 (Conv2D)         (None, 224, 224, 64)      1792      \n                                                                 \n zero_padding2d_144 (ZeroPad  (None, 226, 226, 64)     0         \n ding2D)                                                         \n                                                                 \n conv2d_167 (Conv2D)         (None, 224, 224, 64)      36928     \n                                                                 \n max_pooling2d_55 (MaxPoolin  (None, 112, 112, 64)     0         \n g2D)                                                            \n                                                                 \n zero_padding2d_145 (ZeroPad  (None, 114, 114, 64)     0         \n ding2D)                                                         \n                                                                 \n conv2d_168 (Conv2D)         (None, 112, 112, 128)     73856     \n                                                                 \n zero_padding2d_146 (ZeroPad  (None, 114, 114, 128)    0         \n ding2D)                                                         \n                                                                 \n conv2d_169 (Conv2D)         (None, 112, 112, 128)     147584    \n                                                                 \n max_pooling2d_56 (MaxPoolin  (None, 56, 56, 128)      0         \n g2D)                                                            \n                                                                 \n zero_padding2d_147 (ZeroPad  (None, 58, 58, 128)      0         \n ding2D)                                                         \n                                                                 \n conv2d_170 (Conv2D)         (None, 56, 56, 256)       295168    \n                                                                 \n zero_padding2d_148 (ZeroPad  (None, 58, 58, 256)      0         \n ding2D)                                                         \n                                                                 \n conv2d_171 (Conv2D)         (None, 56, 56, 256)       590080    \n                                                                 \n zero_padding2d_149 (ZeroPad  (None, 58, 58, 256)      0         \n ding2D)                                                         \n                                                                 \n conv2d_172 (Conv2D)         (None, 56, 56, 256)       590080    \n                                                                 \n max_pooling2d_57 (MaxPoolin  (None, 28, 28, 256)      0         \n g2D)                                                            \n                                                                 \n zero_padding2d_150 (ZeroPad  (None, 30, 30, 256)      0         \n ding2D)                                                         \n                                                                 \n conv2d_173 (Conv2D)         (None, 28, 28, 512)       1180160   \n                                                                 \n zero_padding2d_151 (ZeroPad  (None, 30, 30, 512)      0         \n ding2D)                                                         \n                                                                 \n conv2d_174 (Conv2D)         (None, 28, 28, 512)       2359808   \n                                                                 \n zero_padding2d_152 (ZeroPad  (None, 30, 30, 512)      0         \n ding2D)                                                         \n                                                                 \n conv2d_175 (Conv2D)         (None, 28, 28, 512)       2359808   \n                                                                 \n max_pooling2d_58 (MaxPoolin  (None, 14, 14, 512)      0         \n g2D)                                                            \n                                                                 \n zero_padding2d_153 (ZeroPad  (None, 16, 16, 512)      0         \n ding2D)                                                         \n                                                                 \n conv2d_176 (Conv2D)         (None, 14, 14, 512)       2359808   \n                                                                 \n zero_padding2d_154 (ZeroPad  (None, 16, 16, 512)      0         \n ding2D)                                                         \n                                                                 \n conv2d_177 (Conv2D)         (None, 14, 14, 512)       2359808   \n                                                                 \n zero_padding2d_155 (ZeroPad  (None, 16, 16, 512)      0         \n ding2D)                                                         \n                                                                 \n conv2d_178 (Conv2D)         (None, 14, 14, 512)       2359808   \n                                                                 \n max_pooling2d_59 (MaxPoolin  (None, 7, 7, 512)        0         \n g2D)                                                            \n                                                                 \n conv2d_179 (Conv2D)         (None, 1, 1, 512)         12845568  \n                                                                 \n dropout_12 (Dropout)        (None, 1, 1, 512)         0         \n                                                                 \n conv2d_180 (Conv2D)         (None, 1, 1, 4096)        2101248   \n                                                                 \n dropout_13 (Dropout)        (None, 1, 1, 4096)        0         \n                                                                 \n conv2d_181 (Conv2D)         (None, 1, 1, 7000)        28679000  \n                                                                 \n flatten_11 (Flatten)        (None, 7000)              0         \n                                                                 \n activation_11 (Activation)  (None, 7000)              0         \n                                                                 \n=================================================================\nTotal params: 58,340,504\nTrainable params: 58,340,504\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train_generator, validation_data=validation_generator, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T19:18:45.027919Z","iopub.execute_input":"2023-11-08T19:18:45.028812Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2023-11-08 19:18:47.490122: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_11/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":" 612/1750 [=========>....................] - ETA: 22:30 - loss: 9.8375 - accuracy: 2.0425e-04","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\n\n# Directory containing test images\ntest_dir = '/kaggle/input/face-classification-deep-learning/dataset/test'\n\n# Initialize a DataFrame to store the results\nresults = []\n\n# Loop over each image in the test directory\nfor img_name in os.listdir(test_dir):\n    img_path = os.path.join(test_dir, img_name)\n    \n    # Load and preprocess the image\n    img = image.load_img(img_path, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n    \n    # Make a prediction\n    predictions = model.predict(img_array)\n    \n    # Get the class with the highest probability\n    predicted_class = np.argmax(predictions)\n    \n    # Append the result to the DataFrame\n    results = results.append(predicted_class)\n    \nres = pd.DataFrame({\"image_name\":os.listdir(test_dir),\"labels\":results})\n\n# Save the results to a CSV file\nres.to_csv('/kaggle/working/predicted_labels.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/face-classification-deep-learning/dataset/train/n000001\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T16:03:04.448397Z","iopub.execute_input":"2023-11-01T16:03:04.449060Z","iopub.status.idle":"2023-11-01T16:03:04.457466Z","shell.execute_reply.started":"2023-11-01T16:03:04.449028Z","shell.execute_reply":"2023-11-01T16:03:04.456515Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['0273_01.jpg',\n '0037_01.jpg',\n '0025_01.jpg',\n '0029_01.jpg',\n '0054_01.jpg',\n '0238_01.jpg',\n '0070_01.jpg',\n '0046_01.jpg',\n '0113_01.jpg',\n '0261_01.jpg',\n '0280_01.jpg',\n '0129_01.jpg',\n '0310_01.jpg',\n '0013_01.jpg',\n '0469_01.jpg',\n '0101_01.jpg',\n '0202_01.jpg',\n '0125_01.jpg',\n '0146_01.jpg',\n '0345_01.jpg']"},"metadata":{}}]},{"cell_type":"code","source":"\nmodel.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\nmodel.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(7000, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}