{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-07T05:39:21.801489Z","iopub.execute_input":"2022-11-07T05:39:21.801952Z","iopub.status.idle":"2022-11-07T05:39:21.994425Z","shell.execute_reply.started":"2022-11-07T05:39:21.801912Z","shell.execute_reply":"2022-11-07T05:39:21.993219Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\",index_col=\"id\")","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:20:29.804997Z","iopub.execute_input":"2022-11-07T05:20:29.806096Z","iopub.status.idle":"2022-11-07T05:20:29.827588Z","shell.execute_reply.started":"2022-11-07T05:20:29.806051Z","shell.execute_reply":"2022-11-07T05:20:29.826310Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:20:31.162654Z","iopub.execute_input":"2022-11-07T05:20:31.165110Z","iopub.status.idle":"2022-11-07T05:20:31.179947Z","shell.execute_reply.started":"2022-11-07T05:20:31.165069Z","shell.execute_reply":"2022-11-07T05:20:31.178549Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 5110 entries, 9046 to 44679\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   gender             5110 non-null   object \n 1   age                5110 non-null   float64\n 2   hypertension       5110 non-null   int64  \n 3   heart_disease      5110 non-null   int64  \n 4   ever_married       5110 non-null   object \n 5   work_type          5110 non-null   object \n 6   Residence_type     5110 non-null   object \n 7   avg_glucose_level  5110 non-null   float64\n 8   bmi                4909 non-null   float64\n 9   smoking_status     5110 non-null   object \n 10  stroke             5110 non-null   int64  \ndtypes: float64(3), int64(3), object(5)\nmemory usage: 479.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.fillna(df.bmi.mean(),inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:20:32.733517Z","iopub.execute_input":"2022-11-07T05:20:32.734201Z","iopub.status.idle":"2022-11-07T05:20:32.741358Z","shell.execute_reply.started":"2022-11-07T05:20:32.734155Z","shell.execute_reply":"2022-11-07T05:20:32.740257Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df1 = df.iloc[:,[0,2,3,4,5,6,9]]\ndf2 = df.iloc[:,[1,7,8]]\ny = df.iloc[:,[-1]]","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:22:30.024101Z","iopub.execute_input":"2022-11-07T05:22:30.025336Z","iopub.status.idle":"2022-11-07T05:22:30.031940Z","shell.execute_reply.started":"2022-11-07T05:22:30.025293Z","shell.execute_reply":"2022-11-07T05:22:30.030928Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler,OneHotEncoder\nohe = OneHotEncoder()\nsc = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:23:47.243841Z","iopub.execute_input":"2022-11-07T05:23:47.244616Z","iopub.status.idle":"2022-11-07T05:23:47.746119Z","shell.execute_reply.started":"2022-11-07T05:23:47.244577Z","shell.execute_reply":"2022-11-07T05:23:47.745148Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(ohe.fit_transform(df1).toarray())\ndf2 = pd.DataFrame(sc.fit_transform(df2))","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:24:09.583153Z","iopub.execute_input":"2022-11-07T05:24:09.584186Z","iopub.status.idle":"2022-11-07T05:24:09.607677Z","shell.execute_reply.started":"2022-11-07T05:24:09.584135Z","shell.execute_reply":"2022-11-07T05:24:09.606660Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df1,df2],axis=1)\ndf.columns = [a for a in range(0,len(df.columns))]","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:24:42.173538Z","iopub.execute_input":"2022-11-07T05:24:42.173955Z","iopub.status.idle":"2022-11-07T05:24:42.180999Z","shell.execute_reply.started":"2022-11-07T05:24:42.173918Z","shell.execute_reply":"2022-11-07T05:24:42.179790Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtr,xte,ytr,yte = train_test_split(df,y,test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:32:36.749600Z","iopub.execute_input":"2022-11-07T05:32:36.750024Z","iopub.status.idle":"2022-11-07T05:32:36.815952Z","shell.execute_reply.started":"2022-11-07T05:32:36.749990Z","shell.execute_reply":"2022-11-07T05:32:36.814761Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nmodel = Sequential()\nmodel.add(Dense(512,activation='relu',input_shape=(23,)))\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation = 'sigmoid'))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.0001), metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:34:32.042844Z","iopub.execute_input":"2022-11-07T05:34:32.045699Z","iopub.status.idle":"2022-11-07T05:34:32.133458Z","shell.execute_reply.started":"2022-11-07T05:34:32.045654Z","shell.execute_reply":"2022-11-07T05:34:32.132146Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_27 (Dense)             (None, 512)               12288     \n_________________________________________________________________\ndense_28 (Dense)             (None, 512)               262656    \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 512)               0         \n_________________________________________________________________\ndense_29 (Dense)             (None, 256)               131328    \n_________________________________________________________________\ndense_30 (Dense)             (None, 256)               65792     \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_31 (Dense)             (None, 128)               32896     \n_________________________________________________________________\ndense_32 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_33 (Dense)             (None, 1)                 129       \n=================================================================\nTotal params: 521,601\nTrainable params: 521,601\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\ncb = EarlyStopping(\n    monitor='accuracy',\n    min_delta=0.001,\n    patience=100,\n    mode='auto')","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:34:33.999977Z","iopub.execute_input":"2022-11-07T05:34:34.000386Z","iopub.status.idle":"2022-11-07T05:34:34.005944Z","shell.execute_reply.started":"2022-11-07T05:34:34.000350Z","shell.execute_reply":"2022-11-07T05:34:34.004642Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model.fit(xtr,ytr,epochs=1000,batch_size=10000,validation_split=0.25,callbacks=cb)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:34:36.491324Z","iopub.execute_input":"2022-11-07T05:34:36.491746Z","iopub.status.idle":"2022-11-07T05:34:56.039795Z","shell.execute_reply.started":"2022-11-07T05:34:36.491708Z","shell.execute_reply":"2022-11-07T05:34:56.038736Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n1/1 [==============================] - 1s 1s/step - loss: 0.7218 - accuracy: 0.3511 - val_loss: 0.6919 - val_accuracy: 0.6054\nEpoch 2/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.7096 - accuracy: 0.4019 - val_loss: 0.6809 - val_accuracy: 0.9144\nEpoch 3/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.6942 - accuracy: 0.5070 - val_loss: 0.6710 - val_accuracy: 0.9415\nEpoch 4/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.6834 - accuracy: 0.5710 - val_loss: 0.6617 - val_accuracy: 0.9426\nEpoch 5/1000\n1/1 [==============================] - 0s 152ms/step - loss: 0.6708 - accuracy: 0.6569 - val_loss: 0.6523 - val_accuracy: 0.9426\nEpoch 6/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.6593 - accuracy: 0.7272 - val_loss: 0.6423 - val_accuracy: 0.9426\nEpoch 7/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.6453 - accuracy: 0.7978 - val_loss: 0.6314 - val_accuracy: 0.9426\nEpoch 8/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.6381 - accuracy: 0.8191 - val_loss: 0.6195 - val_accuracy: 0.9426\nEpoch 9/1000\n1/1 [==============================] - 0s 142ms/step - loss: 0.6235 - accuracy: 0.8636 - val_loss: 0.6065 - val_accuracy: 0.9426\nEpoch 10/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.6089 - accuracy: 0.8880 - val_loss: 0.5925 - val_accuracy: 0.9426\nEpoch 11/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.5965 - accuracy: 0.8998 - val_loss: 0.5776 - val_accuracy: 0.9426\nEpoch 12/1000\n1/1 [==============================] - 0s 152ms/step - loss: 0.5802 - accuracy: 0.9255 - val_loss: 0.5618 - val_accuracy: 0.9426\nEpoch 13/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.5637 - accuracy: 0.9339 - val_loss: 0.5454 - val_accuracy: 0.9426\nEpoch 14/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.5476 - accuracy: 0.9419 - val_loss: 0.5283 - val_accuracy: 0.9426\nEpoch 15/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.5298 - accuracy: 0.9426 - val_loss: 0.5105 - val_accuracy: 0.9426\nEpoch 16/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.5138 - accuracy: 0.9464 - val_loss: 0.4922 - val_accuracy: 0.9426\nEpoch 17/1000\n1/1 [==============================] - 0s 153ms/step - loss: 0.4916 - accuracy: 0.9471 - val_loss: 0.4733 - val_accuracy: 0.9426\nEpoch 18/1000\n1/1 [==============================] - 0s 149ms/step - loss: 0.4760 - accuracy: 0.9485 - val_loss: 0.4539 - val_accuracy: 0.9426\nEpoch 19/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.4545 - accuracy: 0.9502 - val_loss: 0.4342 - val_accuracy: 0.9426\nEpoch 20/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.4332 - accuracy: 0.9509 - val_loss: 0.4143 - val_accuracy: 0.9426\nEpoch 21/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.4147 - accuracy: 0.9506 - val_loss: 0.3941 - val_accuracy: 0.9426\nEpoch 22/1000\n1/1 [==============================] - 0s 149ms/step - loss: 0.3948 - accuracy: 0.9509 - val_loss: 0.3741 - val_accuracy: 0.9426\nEpoch 23/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.3762 - accuracy: 0.9513 - val_loss: 0.3543 - val_accuracy: 0.9426\nEpoch 24/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.3551 - accuracy: 0.9513 - val_loss: 0.3350 - val_accuracy: 0.9426\nEpoch 25/1000\n1/1 [==============================] - 0s 153ms/step - loss: 0.3282 - accuracy: 0.9516 - val_loss: 0.3164 - val_accuracy: 0.9426\nEpoch 26/1000\n1/1 [==============================] - 0s 173ms/step - loss: 0.3126 - accuracy: 0.9513 - val_loss: 0.2987 - val_accuracy: 0.9426\nEpoch 27/1000\n1/1 [==============================] - 0s 156ms/step - loss: 0.2968 - accuracy: 0.9516 - val_loss: 0.2822 - val_accuracy: 0.9426\nEpoch 28/1000\n1/1 [==============================] - 0s 150ms/step - loss: 0.2815 - accuracy: 0.9516 - val_loss: 0.2672 - val_accuracy: 0.9426\nEpoch 29/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.2659 - accuracy: 0.9513 - val_loss: 0.2538 - val_accuracy: 0.9426\nEpoch 30/1000\n1/1 [==============================] - 0s 163ms/step - loss: 0.2514 - accuracy: 0.9516 - val_loss: 0.2423 - val_accuracy: 0.9426\nEpoch 31/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.2404 - accuracy: 0.9516 - val_loss: 0.2328 - val_accuracy: 0.9426\nEpoch 32/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.2298 - accuracy: 0.9516 - val_loss: 0.2252 - val_accuracy: 0.9426\nEpoch 33/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.2207 - accuracy: 0.9516 - val_loss: 0.2196 - val_accuracy: 0.9426\nEpoch 34/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.2207 - accuracy: 0.9516 - val_loss: 0.2158 - val_accuracy: 0.9426\nEpoch 35/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.2086 - accuracy: 0.9516 - val_loss: 0.2137 - val_accuracy: 0.9426\nEpoch 36/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.2068 - accuracy: 0.9516 - val_loss: 0.2128 - val_accuracy: 0.9426\nEpoch 37/1000\n1/1 [==============================] - 0s 142ms/step - loss: 0.2022 - accuracy: 0.9516 - val_loss: 0.2131 - val_accuracy: 0.9426\nEpoch 38/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.2081 - accuracy: 0.9516 - val_loss: 0.2140 - val_accuracy: 0.9426\nEpoch 39/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.2014 - accuracy: 0.9516 - val_loss: 0.2154 - val_accuracy: 0.9426\nEpoch 40/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.2037 - accuracy: 0.9516 - val_loss: 0.2169 - val_accuracy: 0.9426\nEpoch 41/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.2066 - accuracy: 0.9516 - val_loss: 0.2183 - val_accuracy: 0.9426\nEpoch 42/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.2054 - accuracy: 0.9516 - val_loss: 0.2194 - val_accuracy: 0.9426\nEpoch 43/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1993 - accuracy: 0.9516 - val_loss: 0.2202 - val_accuracy: 0.9426\nEpoch 44/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.2044 - accuracy: 0.9516 - val_loss: 0.2206 - val_accuracy: 0.9426\nEpoch 45/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.2041 - accuracy: 0.9516 - val_loss: 0.2205 - val_accuracy: 0.9426\nEpoch 46/1000\n1/1 [==============================] - 0s 142ms/step - loss: 0.2080 - accuracy: 0.9516 - val_loss: 0.2199 - val_accuracy: 0.9426\nEpoch 47/1000\n1/1 [==============================] - 0s 149ms/step - loss: 0.2110 - accuracy: 0.9516 - val_loss: 0.2187 - val_accuracy: 0.9426\nEpoch 48/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1979 - accuracy: 0.9516 - val_loss: 0.2173 - val_accuracy: 0.9426\nEpoch 49/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.2108 - accuracy: 0.9516 - val_loss: 0.2154 - val_accuracy: 0.9426\nEpoch 50/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.2024 - accuracy: 0.9516 - val_loss: 0.2133 - val_accuracy: 0.9426\nEpoch 51/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.2033 - accuracy: 0.9516 - val_loss: 0.2111 - val_accuracy: 0.9426\nEpoch 52/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1979 - accuracy: 0.9516 - val_loss: 0.2088 - val_accuracy: 0.9426\nEpoch 53/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.2004 - accuracy: 0.9516 - val_loss: 0.2065 - val_accuracy: 0.9426\nEpoch 54/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1929 - accuracy: 0.9516 - val_loss: 0.2042 - val_accuracy: 0.9426\nEpoch 55/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.2004 - accuracy: 0.9516 - val_loss: 0.2020 - val_accuracy: 0.9426\nEpoch 56/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1933 - accuracy: 0.9516 - val_loss: 0.2000 - val_accuracy: 0.9426\nEpoch 57/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1920 - accuracy: 0.9516 - val_loss: 0.1981 - val_accuracy: 0.9426\nEpoch 58/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1885 - accuracy: 0.9516 - val_loss: 0.1964 - val_accuracy: 0.9426\nEpoch 59/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1889 - accuracy: 0.9516 - val_loss: 0.1949 - val_accuracy: 0.9426\nEpoch 60/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1852 - accuracy: 0.9516 - val_loss: 0.1935 - val_accuracy: 0.9426\nEpoch 61/1000\n1/1 [==============================] - 0s 150ms/step - loss: 0.1894 - accuracy: 0.9516 - val_loss: 0.1923 - val_accuracy: 0.9426\nEpoch 62/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1811 - accuracy: 0.9516 - val_loss: 0.1913 - val_accuracy: 0.9426\nEpoch 63/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1846 - accuracy: 0.9516 - val_loss: 0.1904 - val_accuracy: 0.9426\nEpoch 64/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1871 - accuracy: 0.9516 - val_loss: 0.1896 - val_accuracy: 0.9426\nEpoch 65/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1864 - accuracy: 0.9516 - val_loss: 0.1889 - val_accuracy: 0.9426\nEpoch 66/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1827 - accuracy: 0.9516 - val_loss: 0.1882 - val_accuracy: 0.9426\nEpoch 67/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1873 - accuracy: 0.9516 - val_loss: 0.1877 - val_accuracy: 0.9426\nEpoch 68/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1767 - accuracy: 0.9516 - val_loss: 0.1871 - val_accuracy: 0.9426\nEpoch 69/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1774 - accuracy: 0.9516 - val_loss: 0.1866 - val_accuracy: 0.9426\nEpoch 70/1000\n1/1 [==============================] - 0s 150ms/step - loss: 0.1801 - accuracy: 0.9516 - val_loss: 0.1860 - val_accuracy: 0.9426\nEpoch 71/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1787 - accuracy: 0.9516 - val_loss: 0.1855 - val_accuracy: 0.9426\nEpoch 72/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1812 - accuracy: 0.9516 - val_loss: 0.1850 - val_accuracy: 0.9426\nEpoch 73/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1827 - accuracy: 0.9516 - val_loss: 0.1845 - val_accuracy: 0.9426\nEpoch 74/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1832 - accuracy: 0.9516 - val_loss: 0.1839 - val_accuracy: 0.9426\nEpoch 75/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1816 - accuracy: 0.9516 - val_loss: 0.1834 - val_accuracy: 0.9426\nEpoch 76/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1801 - accuracy: 0.9516 - val_loss: 0.1829 - val_accuracy: 0.9426\nEpoch 77/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1852 - accuracy: 0.9516 - val_loss: 0.1824 - val_accuracy: 0.9426\nEpoch 78/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1790 - accuracy: 0.9516 - val_loss: 0.1819 - val_accuracy: 0.9426\nEpoch 79/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1802 - accuracy: 0.9516 - val_loss: 0.1814 - val_accuracy: 0.9426\nEpoch 80/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1767 - accuracy: 0.9516 - val_loss: 0.1809 - val_accuracy: 0.9426\nEpoch 81/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1754 - accuracy: 0.9516 - val_loss: 0.1805 - val_accuracy: 0.9426\nEpoch 82/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1756 - accuracy: 0.9516 - val_loss: 0.1800 - val_accuracy: 0.9426\nEpoch 83/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1785 - accuracy: 0.9516 - val_loss: 0.1796 - val_accuracy: 0.9426\nEpoch 84/1000\n1/1 [==============================] - 0s 153ms/step - loss: 0.1723 - accuracy: 0.9516 - val_loss: 0.1792 - val_accuracy: 0.9426\nEpoch 85/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1784 - accuracy: 0.9516 - val_loss: 0.1788 - val_accuracy: 0.9426\nEpoch 86/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1740 - accuracy: 0.9516 - val_loss: 0.1784 - val_accuracy: 0.9426\nEpoch 87/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1790 - accuracy: 0.9516 - val_loss: 0.1781 - val_accuracy: 0.9426\nEpoch 88/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1743 - accuracy: 0.9516 - val_loss: 0.1777 - val_accuracy: 0.9426\nEpoch 89/1000\n1/1 [==============================] - 0s 143ms/step - loss: 0.1736 - accuracy: 0.9516 - val_loss: 0.1774 - val_accuracy: 0.9426\nEpoch 90/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1704 - accuracy: 0.9516 - val_loss: 0.1771 - val_accuracy: 0.9426\nEpoch 91/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1719 - accuracy: 0.9516 - val_loss: 0.1768 - val_accuracy: 0.9426\nEpoch 92/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1762 - accuracy: 0.9516 - val_loss: 0.1765 - val_accuracy: 0.9426\nEpoch 93/1000\n1/1 [==============================] - 0s 151ms/step - loss: 0.1684 - accuracy: 0.9516 - val_loss: 0.1762 - val_accuracy: 0.9426\nEpoch 94/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1702 - accuracy: 0.9516 - val_loss: 0.1759 - val_accuracy: 0.9426\nEpoch 95/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1729 - accuracy: 0.9516 - val_loss: 0.1757 - val_accuracy: 0.9426\nEpoch 96/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1766 - accuracy: 0.9516 - val_loss: 0.1754 - val_accuracy: 0.9426\nEpoch 97/1000\n1/1 [==============================] - 0s 147ms/step - loss: 0.1693 - accuracy: 0.9516 - val_loss: 0.1751 - val_accuracy: 0.9426\nEpoch 98/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1731 - accuracy: 0.9516 - val_loss: 0.1749 - val_accuracy: 0.9426\nEpoch 99/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1725 - accuracy: 0.9516 - val_loss: 0.1746 - val_accuracy: 0.9426\nEpoch 100/1000\n1/1 [==============================] - 0s 164ms/step - loss: 0.1703 - accuracy: 0.9516 - val_loss: 0.1744 - val_accuracy: 0.9426\nEpoch 101/1000\n1/1 [==============================] - 0s 149ms/step - loss: 0.1728 - accuracy: 0.9516 - val_loss: 0.1741 - val_accuracy: 0.9426\nEpoch 102/1000\n1/1 [==============================] - 0s 145ms/step - loss: 0.1681 - accuracy: 0.9516 - val_loss: 0.1739 - val_accuracy: 0.9426\nEpoch 103/1000\n1/1 [==============================] - 0s 144ms/step - loss: 0.1659 - accuracy: 0.9516 - val_loss: 0.1737 - val_accuracy: 0.9426\nEpoch 104/1000\n1/1 [==============================] - 0s 172ms/step - loss: 0.1669 - accuracy: 0.9516 - val_loss: 0.1736 - val_accuracy: 0.9426\nEpoch 105/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1678 - accuracy: 0.9516 - val_loss: 0.1734 - val_accuracy: 0.9426\nEpoch 106/1000\n1/1 [==============================] - 0s 150ms/step - loss: 0.1676 - accuracy: 0.9516 - val_loss: 0.1732 - val_accuracy: 0.9426\nEpoch 107/1000\n1/1 [==============================] - 0s 150ms/step - loss: 0.1695 - accuracy: 0.9516 - val_loss: 0.1731 - val_accuracy: 0.9426\nEpoch 108/1000\n1/1 [==============================] - 0s 149ms/step - loss: 0.1707 - accuracy: 0.9516 - val_loss: 0.1729 - val_accuracy: 0.9426\nEpoch 109/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1671 - accuracy: 0.9516 - val_loss: 0.1728 - val_accuracy: 0.9426\nEpoch 110/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1660 - accuracy: 0.9516 - val_loss: 0.1726 - val_accuracy: 0.9426\nEpoch 111/1000\n1/1 [==============================] - 0s 151ms/step - loss: 0.1680 - accuracy: 0.9516 - val_loss: 0.1725 - val_accuracy: 0.9426\nEpoch 112/1000\n1/1 [==============================] - 0s 156ms/step - loss: 0.1654 - accuracy: 0.9516 - val_loss: 0.1724 - val_accuracy: 0.9426\nEpoch 113/1000\n1/1 [==============================] - 0s 153ms/step - loss: 0.1676 - accuracy: 0.9516 - val_loss: 0.1723 - val_accuracy: 0.9426\nEpoch 114/1000\n1/1 [==============================] - 0s 154ms/step - loss: 0.1682 - accuracy: 0.9516 - val_loss: 0.1722 - val_accuracy: 0.9426\nEpoch 115/1000\n1/1 [==============================] - 0s 149ms/step - loss: 0.1717 - accuracy: 0.9516 - val_loss: 0.1721 - val_accuracy: 0.9426\nEpoch 116/1000\n1/1 [==============================] - 0s 152ms/step - loss: 0.1650 - accuracy: 0.9516 - val_loss: 0.1720 - val_accuracy: 0.9426\nEpoch 117/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1690 - accuracy: 0.9516 - val_loss: 0.1719 - val_accuracy: 0.9426\nEpoch 118/1000\n1/1 [==============================] - 0s 148ms/step - loss: 0.1610 - accuracy: 0.9516 - val_loss: 0.1718 - val_accuracy: 0.9426\nEpoch 119/1000\n1/1 [==============================] - 0s 152ms/step - loss: 0.1656 - accuracy: 0.9516 - val_loss: 0.1717 - val_accuracy: 0.9426\nEpoch 120/1000\n1/1 [==============================] - 0s 151ms/step - loss: 0.1654 - accuracy: 0.9516 - val_loss: 0.1717 - val_accuracy: 0.9426\nEpoch 121/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1608 - accuracy: 0.9516 - val_loss: 0.1716 - val_accuracy: 0.9426\nEpoch 122/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1698 - accuracy: 0.9516 - val_loss: 0.1715 - val_accuracy: 0.9426\nEpoch 123/1000\n1/1 [==============================] - 0s 146ms/step - loss: 0.1668 - accuracy: 0.9516 - val_loss: 0.1715 - val_accuracy: 0.9426\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f1551b1bed0>"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(xte,yte)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T05:41:46.811008Z","iopub.execute_input":"2022-11-07T05:41:46.812110Z","iopub.status.idle":"2022-11-07T05:41:46.993005Z","shell.execute_reply.started":"2022-11-07T05:41:46.812051Z","shell.execute_reply":"2022-11-07T05:41:46.991958Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"40/40 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9570\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"[0.1468483805656433, 0.9569640159606934]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}