{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, shutil\nos.mkdir(\"/kaggle/working/train\")\nos.mkdir(\"/kaggle/working/validation\")","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:06:58.645850Z","iopub.execute_input":"2023-10-26T20:06:58.646647Z","iopub.status.idle":"2023-10-26T20:06:58.650914Z","shell.execute_reply.started":"2023-10-26T20:06:58.646613Z","shell.execute_reply":"2023-10-26T20:06:58.650031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shutil.copytree(train_dir,os.path.join(\"/kaggle/working/train\", os.path.basename(\"/kaggle/input/face-classification-deep-learning/dataset/train\")))\ntrain_dir = \"/kaggle/input/face-classification-deep-learning/dataset/train\"\n\n\"\"\"val_dir = \"/kaggle/working/validation\"\nfor a in os.listdir(train_dir):\n    person = os.path.join(train_dir,a)\n    lop = os.listdir(person)\n    os.mkdir(os.path.join(\"/kaggle/working/validation\",a))\n    for x in lop[-12:-8]:\n        print(os.path.join(person,x))\n        print(os.path.join(val_dir,a,x))\n        shutil.(os.path.join(person,x),os.path.join(val_dir,a,x))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:15:38.466906Z","iopub.execute_input":"2023-10-26T20:15:38.467250Z","iopub.status.idle":"2023-10-26T20:15:38.473749Z","shell.execute_reply.started":"2023-10-26T20:15:38.467223Z","shell.execute_reply":"2023-10-26T20:15:38.472834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import models\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu',\ninput_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))\nmodel.add(layers.Dense(7000, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:41:04.933921Z","iopub.execute_input":"2023-10-26T20:41:04.934294Z","iopub.status.idle":"2023-10-26T20:41:05.042574Z","shell.execute_reply.started":"2023-10-26T20:41:04.934266Z","shell.execute_reply":"2023-10-26T20:41:05.041639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:41:06.452167Z","iopub.execute_input":"2023-10-26T20:41:06.452566Z","iopub.status.idle":"2023-10-26T20:41:06.485577Z","shell.execute_reply.started":"2023-10-26T20:41:06.452535Z","shell.execute_reply":"2023-10-26T20:41:06.484726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:41:13.332466Z","iopub.execute_input":"2023-10-26T20:41:13.332825Z","iopub.status.idle":"2023-10-26T20:41:13.345324Z","shell.execute_reply.started":"2023-10-26T20:41:13.332798Z","shell.execute_reply":"2023-10-26T20:41:13.344442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255,rotation_range=45,shear_range=0.4,zoom_range=0.4,horizontal_flip=True,validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical')\n\"\"\"validation_generator = test_datagen.flow_from_directory(validation_dir,\n                                                        target_size=(150, 150),\n                                                        batch_size=20,\n                                                        class_mode='categorical')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:45:43.925037Z","iopub.execute_input":"2023-10-26T20:45:43.925401Z","iopub.status.idle":"2023-10-26T20:45:58.023389Z","shell.execute_reply.started":"2023-10-26T20:45:43.925374Z","shell.execute_reply":"2023-10-26T20:45:58.022429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch=1000,\n    epochs=100,\n    )#validation_data=validation_generator,validation_steps=50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Load your dataset\n#rescale=1./255\ntrain_datagen = ImageDataGenerator(validation_split=0.2)\ntrain_generator = train_datagen.flow_from_directory(\n        '/kaggle/input/face-classification-deep-learning/dataset/train',\n        target_size=(224, 224),\n        batch_size=256,\n        class_mode='categorical',\n        subset='training')\nvalidation_generator = train_datagen.flow_from_directory(\n        '/kaggle/input/face-classification-deep-learning/dataset/train',\n        target_size=(224, 224),\n        batch_size=256,\n        class_mode='categorical',\n        subset='validation')\n\n# Define the model\nbase_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze the convolutional base\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(7000, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(train_generator, validation_data=validation_generator, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T07:05:53.691617Z","iopub.execute_input":"2023-10-27T07:05:53.692275Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Found 112000 images belonging to 7000 classes.\nFound 28000 images belonging to 7000 classes.\nEpoch 1/10\n438/438 [==============================] - 429s 971ms/step - loss: 8.6335 - accuracy: 0.0152 - val_loss: 6.9308 - val_accuracy: 0.0580\nEpoch 2/10\n438/438 [==============================] - 424s 968ms/step - loss: 5.2854 - accuracy: 0.1818 - val_loss: 6.2111 - val_accuracy: 0.1082\nEpoch 3/10\n438/438 [==============================] - 426s 973ms/step - loss: 3.6086 - accuracy: 0.3949 - val_loss: 5.8277 - val_accuracy: 0.1380\nEpoch 4/10\n438/438 [==============================] - 426s 973ms/step - loss: 2.4876 - accuracy: 0.5822 - val_loss: 5.6032 - val_accuracy: 0.1635\nEpoch 5/10\n438/438 [==============================] - 425s 969ms/step - loss: 1.7242 - accuracy: 0.7266 - val_loss: 5.4489 - val_accuracy: 0.1783\nEpoch 6/10\n438/438 [==============================] - 424s 968ms/step - loss: 1.1931 - accuracy: 0.8319 - val_loss: 5.3312 - val_accuracy: 0.1964\nEpoch 7/10\n438/438 [==============================] - 425s 968ms/step - loss: 0.8147 - accuracy: 0.9026 - val_loss: 5.2205 - val_accuracy: 0.2043\nEpoch 8/10\n438/438 [==============================] - 427s 975ms/step - loss: 0.5517 - accuracy: 0.9490 - val_loss: 5.1670 - val_accuracy: 0.2136\nEpoch 9/10\n 86/438 [====>.........................] - ETA: 4:34 - loss: 0.3282 - accuracy: 0.9816","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}