{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, shutil\nos.mkdir(\"/kaggle/working/train\")\nos.mkdir(\"/kaggle/working/validation\")","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:06:58.645850Z","iopub.execute_input":"2023-10-26T20:06:58.646647Z","iopub.status.idle":"2023-10-26T20:06:58.650914Z","shell.execute_reply.started":"2023-10-26T20:06:58.646613Z","shell.execute_reply":"2023-10-26T20:06:58.650031Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#shutil.copytree(train_dir,os.path.join(\"/kaggle/working/train\", os.path.basename(\"/kaggle/input/face-classification-deep-learning/dataset/train\")))\ntrain_dir = \"/kaggle/input/face-classification-deep-learning/dataset/train\"\n\n\"\"\"val_dir = \"/kaggle/working/validation\"\nfor a in os.listdir(train_dir):\n    person = os.path.join(train_dir,a)\n    lop = os.listdir(person)\n    os.mkdir(os.path.join(\"/kaggle/working/validation\",a))\n    for x in lop[-12:-8]:\n        print(os.path.join(person,x))\n        print(os.path.join(val_dir,a,x))\n        shutil.(os.path.join(person,x),os.path.join(val_dir,a,x))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:15:38.466906Z","iopub.execute_input":"2023-10-26T20:15:38.467250Z","iopub.status.idle":"2023-10-26T20:15:38.473749Z","shell.execute_reply.started":"2023-10-26T20:15:38.467223Z","shell.execute_reply":"2023-10-26T20:15:38.472834Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'val_dir = \"/kaggle/working/validation\"\\nfor a in os.listdir(train_dir):\\n    person = os.path.join(train_dir,a)\\n    lop = os.listdir(person)\\n    os.mkdir(os.path.join(\"/kaggle/working/validation\",a))\\n    for x in lop[-12:-8]:\\n        print(os.path.join(person,x))\\n        print(os.path.join(val_dir,a,x))\\n        shutil.(os.path.join(person,x),os.path.join(val_dir,a,x))'"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import models\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu',\ninput_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(2048, activation='relu'))\nmodel.add(layers.Dense(7000, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:41:04.933921Z","iopub.execute_input":"2023-10-26T20:41:04.934294Z","iopub.status.idle":"2023-10-26T20:41:05.042574Z","shell.execute_reply.started":"2023-10-26T20:41:04.934266Z","shell.execute_reply":"2023-10-26T20:41:05.041639Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:41:06.452167Z","iopub.execute_input":"2023-10-26T20:41:06.452566Z","iopub.status.idle":"2023-10-26T20:41:06.485577Z","shell.execute_reply.started":"2023-10-26T20:41:06.452535Z","shell.execute_reply":"2023-10-26T20:41:06.484726Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_8 (Conv2D)           (None, 148, 148, 512)     14336     \n                                                                 \n max_pooling2d_8 (MaxPooling  (None, 74, 74, 512)      0         \n 2D)                                                             \n                                                                 \n conv2d_9 (Conv2D)           (None, 72, 72, 256)       1179904   \n                                                                 \n max_pooling2d_9 (MaxPooling  (None, 36, 36, 256)      0         \n 2D)                                                             \n                                                                 \n conv2d_10 (Conv2D)          (None, 34, 34, 128)       295040    \n                                                                 \n max_pooling2d_10 (MaxPoolin  (None, 17, 17, 128)      0         \n g2D)                                                            \n                                                                 \n conv2d_11 (Conv2D)          (None, 15, 15, 128)       147584    \n                                                                 \n max_pooling2d_11 (MaxPoolin  (None, 7, 7, 128)        0         \n g2D)                                                            \n                                                                 \n flatten_2 (Flatten)         (None, 6272)              0         \n                                                                 \n dense_4 (Dense)             (None, 2048)              12847104  \n                                                                 \n dense_5 (Dense)             (None, 7000)              14343000  \n                                                                 \n=================================================================\nTotal params: 28,826,968\nTrainable params: 28,826,968\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:41:13.332466Z","iopub.execute_input":"2023-10-26T20:41:13.332825Z","iopub.status.idle":"2023-10-26T20:41:13.345324Z","shell.execute_reply.started":"2023-10-26T20:41:13.332798Z","shell.execute_reply":"2023-10-26T20:41:13.344442Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255,rotation_range=45,shear_range=0.4,zoom_range=0.4,horizontal_flip=True,validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='categorical')\n\"\"\"validation_generator = test_datagen.flow_from_directory(validation_dir,\n                                                        target_size=(150, 150),\n                                                        batch_size=20,\n                                                        class_mode='categorical')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-10-26T20:45:43.925037Z","iopub.execute_input":"2023-10-26T20:45:43.925401Z","iopub.status.idle":"2023-10-26T20:45:58.023389Z","shell.execute_reply.started":"2023-10-26T20:45:43.925374Z","shell.execute_reply":"2023-10-26T20:45:58.022429Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Found 140000 images belonging to 7000 classes.\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"\"validation_generator = test_datagen.flow_from_directory(validation_dir,\\n                                                        target_size=(150, 150),\\n                                                        batch_size=20,\\n                                                        class_mode='categorical')\""},"metadata":{}}]},{"cell_type":"code","source":"history = model.fit_generator(\n    train_generator,\n    steps_per_epoch=1000,\n    epochs=100,\n    )#validation_data=validation_generator,validation_steps=50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}